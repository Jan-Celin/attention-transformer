# Transformer

A flexible Pytorch implementation of the transformer architecture.

## Motivation

Motivated by a lack of libraries that offer good and flexible implementations of the attention-based transfomer architecture, as well as the wish to learn about the architecture's implementation, I decided to develop a Python transformer module.

The goal is to develop an intuitive, flexible and modular transformer module which allows easy implementations of attention-based models in any domain (language, vision, music, etc.).

The module is still in early development.
